{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_validate, RepeatedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/admin/Desktop/研究生/Sem1/DSS5104/Project data/combined_B_&_C.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date      price  bedrooms  bathrooms  sqft_living  sqft_lot  floors  \\\n",
      "0  2014-05-02   313000.0       3.0       1.50         1340      7912     1.5   \n",
      "1  2014-05-02  2384000.0       5.0       2.50         3650      9050     2.0   \n",
      "2  2014-05-02   342000.0       3.0       2.00         1930     11947     1.0   \n",
      "3  2014-05-02   420000.0       3.0       2.25         2000      8030     1.0   \n",
      "4  2014-05-02   550000.0       4.0       2.50         1940     10500     1.0   \n",
      "\n",
      "   waterfront  view  condition  ...  city_grouped_SeaTac  \\\n",
      "0           0     0          3  ...                False   \n",
      "1           0     4          5  ...                False   \n",
      "2           0     0          4  ...                False   \n",
      "3           0     0          4  ...                False   \n",
      "4           0     0          4  ...                False   \n",
      "\n",
      "   city_grouped_Seattle  city_grouped_Shoreline  city_grouped_Snoqualmie  \\\n",
      "0                 False                    True                    False   \n",
      "1                  True                   False                    False   \n",
      "2                 False                   False                    False   \n",
      "3                 False                   False                    False   \n",
      "4                 False                   False                    False   \n",
      "\n",
      "  city_grouped_Tukwila city_grouped_Vashon city_grouped_Woodinville  \\\n",
      "0                False               False                    False   \n",
      "1                False               False                    False   \n",
      "2                False               False                    False   \n",
      "3                False               False                    False   \n",
      "4                False               False                    False   \n",
      "\n",
      "  knn_avg_price  zipcode_price_tier_Medium  zipcode_price_tier_High  \n",
      "0      312600.0                      False                    False  \n",
      "1     1180800.0                      False                     True  \n",
      "2      360360.0                      False                    False  \n",
      "3      455780.0                       True                    False  \n",
      "4      499120.0                      False                     True  \n",
      "\n",
      "[5 rows x 79 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9102 entries, 0 to 9199\n",
      "Data columns (total 69 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   price                          9102 non-null   float64\n",
      " 1   bedrooms                       9102 non-null   float64\n",
      " 2   bathrooms                      9102 non-null   float64\n",
      " 3   sqft_lot                       9102 non-null   int64  \n",
      " 4   floors                         9102 non-null   float64\n",
      " 5   waterfront                     9102 non-null   int64  \n",
      " 6   view                           9102 non-null   int64  \n",
      " 7   condition                      9102 non-null   int64  \n",
      " 8   yr_built                       9102 non-null   int64  \n",
      " 9   yr_renovated                   9102 non-null   int64  \n",
      " 10  log_price                      9102 non-null   float64\n",
      " 11  yr_after_renovated             9102 non-null   int64  \n",
      " 12  yr_after_built                 9102 non-null   int64  \n",
      " 13  price_per_sqft                 9102 non-null   float64\n",
      " 14  basement_present               9102 non-null   int64  \n",
      " 15  if_renovated                   9102 non-null   int64  \n",
      " 16  if_waterfront                  9102 non-null   int64  \n",
      " 17  basement_ratio                 9102 non-null   float64\n",
      " 18  sqft_above_ratio               9102 non-null   float64\n",
      " 19  rooms                          9102 non-null   float64\n",
      " 20  yr_renovated_bin               0 non-null      float64\n",
      " 21  log_sqft_living                9102 non-null   float64\n",
      " 22  log_sqft_above                 9102 non-null   float64\n",
      " 23  log_sqft_basement              9102 non-null   float64\n",
      " 24  zipcode                        9102 non-null   int64  \n",
      " 25  city_avg_price                 9102 non-null   float64\n",
      " 26  zipcode_avg_price              9102 non-null   float64\n",
      " 27  city_grouped_Auburn            9102 non-null   int64  \n",
      " 28  city_grouped_Bellevue          9102 non-null   int64  \n",
      " 29  city_grouped_Black Diamond     9102 non-null   int64  \n",
      " 30  city_grouped_Bothell           9102 non-null   int64  \n",
      " 31  city_grouped_Burien            9102 non-null   int64  \n",
      " 32  city_grouped_Carnation         9102 non-null   int64  \n",
      " 33  city_grouped_Clyde Hill        9102 non-null   int64  \n",
      " 34  city_grouped_Covington         9102 non-null   int64  \n",
      " 35  city_grouped_Des Moines        9102 non-null   int64  \n",
      " 36  city_grouped_Duvall            9102 non-null   int64  \n",
      " 37  city_grouped_Enumclaw          9102 non-null   int64  \n",
      " 38  city_grouped_Fall City         9102 non-null   int64  \n",
      " 39  city_grouped_Federal Way       9102 non-null   int64  \n",
      " 40  city_grouped_Issaquah          9102 non-null   int64  \n",
      " 41  city_grouped_Kenmore           9102 non-null   int64  \n",
      " 42  city_grouped_Kent              9102 non-null   int64  \n",
      " 43  city_grouped_Kirkland          9102 non-null   int64  \n",
      " 44  city_grouped_Lake Forest Park  9102 non-null   int64  \n",
      " 45  city_grouped_Maple Valley      9102 non-null   int64  \n",
      " 46  city_grouped_Medina            9102 non-null   int64  \n",
      " 47  city_grouped_Mercer Island     9102 non-null   int64  \n",
      " 48  city_grouped_Newcastle         9102 non-null   int64  \n",
      " 49  city_grouped_Normandy Park     9102 non-null   int64  \n",
      " 50  city_grouped_North Bend        9102 non-null   int64  \n",
      " 51  city_grouped_Other             9102 non-null   int64  \n",
      " 52  city_grouped_Pacific           9102 non-null   int64  \n",
      " 53  city_grouped_Ravensdale        9102 non-null   int64  \n",
      " 54  city_grouped_Redmond           9102 non-null   int64  \n",
      " 55  city_grouped_Renton            9102 non-null   int64  \n",
      " 56  city_grouped_Sammamish         9102 non-null   int64  \n",
      " 57  city_grouped_SeaTac            9102 non-null   int64  \n",
      " 58  city_grouped_Seattle           9102 non-null   int64  \n",
      " 59  city_grouped_Shoreline         9102 non-null   int64  \n",
      " 60  city_grouped_Snoqualmie        9102 non-null   int64  \n",
      " 61  city_grouped_Tukwila           9102 non-null   int64  \n",
      " 62  city_grouped_Vashon            9102 non-null   int64  \n",
      " 63  city_grouped_Woodinville       9102 non-null   int64  \n",
      " 64  knn_avg_price                  9102 non-null   float64\n",
      " 65  zipcode_price_tier_Medium      9102 non-null   int64  \n",
      " 66  zipcode_price_tier_High        9102 non-null   int64  \n",
      " 67  floors_bin_2                   9102 non-null   int64  \n",
      " 68  floors_bin_3+                  9102 non-null   int64  \n",
      "dtypes: float64(16), int64(53)\n",
      "memory usage: 4.9 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace infinite values with NaN in the entire DataFrame\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Define target and features\n",
    "# We use log_price as the target and remove both 'price' and 'log_price' from the features\n",
    "target_col = 'log_price'\n",
    "df.dropna(subset=[target_col], inplace=True)  # ensure no missing target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data Cleaning\n",
    "# Drop non-numeric columns that are not needed for regression\n",
    "cols_to_drop = ['date', 'street', 'city', 'statezip', 'country', 'bedrooms_bin', 'bathrooms_bin', 'yr_built_bin', 'sqft_living', 'sqft_above', 'sqft_basement']\n",
    "df.drop(columns=cols_to_drop, errors='ignore', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Definefeatures\n",
    "\n",
    "X = df.drop(columns=['price', 'log_price'], errors='ignore')\n",
    "y = df[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'yr_renovated_bin' in X.columns:\n",
    "    X.drop(columns=['yr_renovated_bin'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the floors_bin column if it exists (since it has values like '1', '2', '3+')\n",
    "if 'floors_bin' in df.columns:\n",
    "    df = pd.get_dummies(df, columns=['floors_bin'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert boolean columns to integers (0/1)\n",
    "df = df.apply(lambda x: x.astype(int) if x.dtype == 'bool' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Optional sanity check\n",
    "print(X.select_dtypes(exclude='number').columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just in case, Ensure X contains only numeric columns (drop any remaining non-numeric features)\n",
    "X = X.select_dtypes(include=[np.number]).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Split the data into training and test sets (80/20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Setup Cross-Validation and scoring metrics\n",
    "cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
    "# Using sklearn's built-in scorers for MAE and RMSE.\n",
    "scoring = {\n",
    "    'MAE': 'neg_mean_absolute_error', \n",
    "    'RMSE': 'neg_root_mean_squared_error'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom wrapper for statsmodels OLS to be used in scikit-learn pipelines\n",
    "class OLSWrapper(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, add_constant=True):\n",
    "        self.add_constant = add_constant\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Add intercept if required (statsmodels does not add it automatically)\n",
    "        if self.add_constant:\n",
    "            X = sm.add_constant(X)\n",
    "        self.model_ = sm.OLS(y, X).fit()\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.add_constant:\n",
    "            # Make sure we add the constant if needed during prediction\n",
    "            # 'has_constant' parameter ensures that a constant column isn’t added twice if it already exists.\n",
    "            X = sm.add_constant(X, has_constant='add')\n",
    "        return self.model_.predict(X)\n",
    "\n",
    "    def summary(self):\n",
    "        return self.model_.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "# 6. Build Pipelines for the three models\n",
    "\n",
    "# (Ordinary Linear Regression)\n",
    "# ols_pipeline = Pipeline([\n",
    "#    ('imputer', SimpleImputer(strategy='median')),\n",
    "#    ('scaler', StandardScaler()),\n",
    "#    ('reg', LinearRegression())\n",
    "#])\n",
    "\n",
    "# Baseline: OLS (Ordinary Least Squares) using our custom OLSWrapper\n",
    "ols_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('reg', OLSWrapper())  # Our custom estimator wrapping statsmodels.OLS\n",
    "])\n",
    "\n",
    "# Ridge Regression with built-in cross-validation for alpha tuning\n",
    "ridge_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('reg', RidgeCV(alphas=[0.01, 0.1, 1, 10, 100], cv=5))\n",
    "])\n",
    "\n",
    "# Lasso Regression with built-in cross-validation for alpha tuning\n",
    "lasso_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('reg', LassoCV(alphas=[0.01, 0.1, 1, 10, 100], cv=5, random_state=42, max_iter=10000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Evaluation function: performs CV and computes test set errors\n",
    "def evaluate_model(pipeline, X_train, y_train, X_test, y_test, scoring, cv):\n",
    "    # Cross-validation on training set\n",
    "    cv_results = cross_validate(pipeline, X_train, y_train, cv=cv, scoring=scoring, return_train_score=True)\n",
    "    \n",
    "    # Fit the pipeline on the full training set\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    # Predict on the test set\n",
    "    y_pred_test = pipeline.predict(X_test)\n",
    "    \n",
    "    # Compute test errors\n",
    "    test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    \n",
    "    # Convert negative scores to positive values\n",
    "    train_mae = -np.mean(cv_results['train_MAE'])\n",
    "    train_rmse = -np.mean(cv_results['train_RMSE'])\n",
    "    cv_mae = -np.mean(cv_results['test_MAE'])\n",
    "    cv_rmse = -np.mean(cv_results['test_RMSE'])\n",
    "    \n",
    "    return {\n",
    "        'Train MAE': train_mae,\n",
    "        'Train RMSE': train_rmse,\n",
    "        'CV MAE': cv_mae,\n",
    "        'CV RMSE': cv_rmse,\n",
    "        'Test MAE': test_mae,\n",
    "        'Test RMSE': test_rmse\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Evaluate each model\n",
    "results_ols   = evaluate_model(ols_pipeline,   X_train, y_train, X_test, y_test, scoring, cv)\n",
    "results_ridge = evaluate_model(ridge_pipeline, X_train, y_train, X_test, y_test, scoring, cv)\n",
    "results_lasso = evaluate_model(lasso_pipeline, X_train, y_train, X_test, y_test, scoring, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation Results:\n",
      "    Model  Train MAE    CV MAE  Test MAE  Train RMSE   CV RMSE  Test RMSE\n",
      "0    OLS   0.161159  0.165279  0.172883    0.239377  0.363121   0.259911\n",
      "1  Ridge   0.161232  0.164905  0.173314    0.238990  0.357968   0.259486\n",
      "2  Lasso   0.209647  0.213785  0.233273    0.291992  0.421131   0.308900\n"
     ]
    }
   ],
   "source": [
    "# 9. Compile results into a summary table\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': ['OLS', 'Ridge', 'Lasso'],\n",
    "    'Train MAE': [results_ols['Train MAE'], results_ridge['Train MAE'], results_lasso['Train MAE']],\n",
    "    'CV MAE': [results_ols['CV MAE'], results_ridge['CV MAE'], results_lasso['CV MAE']],\n",
    "    'Test MAE': [results_ols['Test MAE'], results_ridge['Test MAE'], results_lasso['Test MAE']],\n",
    "    'Train RMSE': [results_ols['Train RMSE'], results_ridge['Train RMSE'], results_lasso['Train RMSE']],\n",
    "    'CV RMSE': [results_ols['CV RMSE'], results_ridge['CV RMSE'], results_lasso['CV RMSE']],\n",
    "    'Test RMSE': [results_ols['Test RMSE'], results_ridge['Test RMSE'], results_lasso['Test RMSE']]\n",
    "})\n",
    "\n",
    "print(\"Model Evaluation Results:\\n\", results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results saved to 'linear_model_evaluation.csv'\n"
     ]
    }
   ],
   "source": [
    "# 10. Save the evaluation table to a CSV file\n",
    "results_df.to_csv('linear_model_evaluation.csv', index=False)\n",
    "print(\"Evaluation results saved to 'linear_model_evaluation.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Model Evaluation Results:\n",
      "OLS Results:\n",
      "  Train MAE: 0.1612\n",
      "  Train RMSE: 0.2394\n",
      "  CV MAE: 0.1653\n",
      "  CV RMSE: 0.3631\n",
      "  Test MAE: 0.1729\n",
      "  Test RMSE: 0.2599\n",
      "  Test R^2: 0.7611\n",
      "\n",
      "Ridge Results:\n",
      "  Train MAE: 0.1612\n",
      "  Train RMSE: 0.2390\n",
      "  CV MAE: 0.1649\n",
      "  CV RMSE: 0.3580\n",
      "  Test MAE: 0.1733\n",
      "  Test RMSE: 0.2595\n",
      "  Test R^2: 0.7619\n",
      "\n",
      "Lasso Results:\n",
      "  Train MAE: 0.2096\n",
      "  Train RMSE: 0.2920\n",
      "  CV MAE: 0.2138\n",
      "  CV RMSE: 0.4211\n",
      "  Test MAE: 0.2333\n",
      "  Test RMSE: 0.3089\n",
      "  Test R^2: 0.6625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Predict on the test set for each model using the already fitted pipelines\n",
    "y_pred_ols   = ols_pipeline.predict(X_test)\n",
    "y_pred_ridge = ridge_pipeline.predict(X_test)\n",
    "y_pred_lasso = lasso_pipeline.predict(X_test)\n",
    "\n",
    "# Calculate R^2 score for each model\n",
    "r2_ols   = r2_score(y_test, y_pred_ols)\n",
    "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
    "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
    "\n",
    "# Print the previously calculated evaluation metrics along with the R^2 score\n",
    "print(\"Detailed Model Evaluation Results:\")\n",
    "print(\"OLS Results:\")\n",
    "print(f\"  Train MAE: {results_ols['Train MAE']:.4f}\")\n",
    "print(f\"  Train RMSE: {results_ols['Train RMSE']:.4f}\")\n",
    "print(f\"  CV MAE: {results_ols['CV MAE']:.4f}\")\n",
    "print(f\"  CV RMSE: {results_ols['CV RMSE']:.4f}\")\n",
    "print(f\"  Test MAE: {results_ols['Test MAE']:.4f}\")\n",
    "print(f\"  Test RMSE: {results_ols['Test RMSE']:.4f}\")\n",
    "print(f\"  Test R^2: {r2_ols:.4f}\\n\")\n",
    "\n",
    "print(\"Ridge Results:\")\n",
    "print(f\"  Train MAE: {results_ridge['Train MAE']:.4f}\")\n",
    "print(f\"  Train RMSE: {results_ridge['Train RMSE']:.4f}\")\n",
    "print(f\"  CV MAE: {results_ridge['CV MAE']:.4f}\")\n",
    "print(f\"  CV RMSE: {results_ridge['CV RMSE']:.4f}\")\n",
    "print(f\"  Test MAE: {results_ridge['Test MAE']:.4f}\")\n",
    "print(f\"  Test RMSE: {results_ridge['Test RMSE']:.4f}\")\n",
    "print(f\"  Test R^2: {r2_ridge:.4f}\\n\")\n",
    "\n",
    "print(\"Lasso Results:\")\n",
    "print(f\"  Train MAE: {results_lasso['Train MAE']:.4f}\")\n",
    "print(f\"  Train RMSE: {results_lasso['Train RMSE']:.4f}\")\n",
    "print(f\"  CV MAE: {results_lasso['CV MAE']:.4f}\")\n",
    "print(f\"  CV RMSE: {results_lasso['CV RMSE']:.4f}\")\n",
    "print(f\"  Test MAE: {results_lasso['Test MAE']:.4f}\")\n",
    "print(f\"  Test RMSE: {results_lasso['Test RMSE']:.4f}\")\n",
    "print(f\"  Test R^2: {r2_lasso:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9102 entries, 0 to 9199\n",
      "Data columns (total 69 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   price                          9102 non-null   float64\n",
      " 1   bedrooms                       9102 non-null   float64\n",
      " 2   bathrooms                      9102 non-null   float64\n",
      " 3   sqft_lot                       9102 non-null   int64  \n",
      " 4   floors                         9102 non-null   float64\n",
      " 5   waterfront                     9102 non-null   int64  \n",
      " 6   view                           9102 non-null   int64  \n",
      " 7   condition                      9102 non-null   int64  \n",
      " 8   yr_built                       9102 non-null   int64  \n",
      " 9   yr_renovated                   9102 non-null   int64  \n",
      " 10  log_price                      9102 non-null   float64\n",
      " 11  yr_after_renovated             9102 non-null   int64  \n",
      " 12  yr_after_built                 9102 non-null   int64  \n",
      " 13  price_per_sqft                 9102 non-null   float64\n",
      " 14  basement_present               9102 non-null   int64  \n",
      " 15  if_renovated                   9102 non-null   int64  \n",
      " 16  if_waterfront                  9102 non-null   int64  \n",
      " 17  basement_ratio                 9102 non-null   float64\n",
      " 18  sqft_above_ratio               9102 non-null   float64\n",
      " 19  rooms                          9102 non-null   float64\n",
      " 20  yr_renovated_bin               0 non-null      float64\n",
      " 21  log_sqft_living                9102 non-null   float64\n",
      " 22  log_sqft_above                 9102 non-null   float64\n",
      " 23  log_sqft_basement              9102 non-null   float64\n",
      " 24  zipcode                        9102 non-null   int64  \n",
      " 25  city_avg_price                 9102 non-null   float64\n",
      " 26  zipcode_avg_price              9102 non-null   float64\n",
      " 27  city_grouped_Auburn            9102 non-null   int64  \n",
      " 28  city_grouped_Bellevue          9102 non-null   int64  \n",
      " 29  city_grouped_Black Diamond     9102 non-null   int64  \n",
      " 30  city_grouped_Bothell           9102 non-null   int64  \n",
      " 31  city_grouped_Burien            9102 non-null   int64  \n",
      " 32  city_grouped_Carnation         9102 non-null   int64  \n",
      " 33  city_grouped_Clyde Hill        9102 non-null   int64  \n",
      " 34  city_grouped_Covington         9102 non-null   int64  \n",
      " 35  city_grouped_Des Moines        9102 non-null   int64  \n",
      " 36  city_grouped_Duvall            9102 non-null   int64  \n",
      " 37  city_grouped_Enumclaw          9102 non-null   int64  \n",
      " 38  city_grouped_Fall City         9102 non-null   int64  \n",
      " 39  city_grouped_Federal Way       9102 non-null   int64  \n",
      " 40  city_grouped_Issaquah          9102 non-null   int64  \n",
      " 41  city_grouped_Kenmore           9102 non-null   int64  \n",
      " 42  city_grouped_Kent              9102 non-null   int64  \n",
      " 43  city_grouped_Kirkland          9102 non-null   int64  \n",
      " 44  city_grouped_Lake Forest Park  9102 non-null   int64  \n",
      " 45  city_grouped_Maple Valley      9102 non-null   int64  \n",
      " 46  city_grouped_Medina            9102 non-null   int64  \n",
      " 47  city_grouped_Mercer Island     9102 non-null   int64  \n",
      " 48  city_grouped_Newcastle         9102 non-null   int64  \n",
      " 49  city_grouped_Normandy Park     9102 non-null   int64  \n",
      " 50  city_grouped_North Bend        9102 non-null   int64  \n",
      " 51  city_grouped_Other             9102 non-null   int64  \n",
      " 52  city_grouped_Pacific           9102 non-null   int64  \n",
      " 53  city_grouped_Ravensdale        9102 non-null   int64  \n",
      " 54  city_grouped_Redmond           9102 non-null   int64  \n",
      " 55  city_grouped_Renton            9102 non-null   int64  \n",
      " 56  city_grouped_Sammamish         9102 non-null   int64  \n",
      " 57  city_grouped_SeaTac            9102 non-null   int64  \n",
      " 58  city_grouped_Seattle           9102 non-null   int64  \n",
      " 59  city_grouped_Shoreline         9102 non-null   int64  \n",
      " 60  city_grouped_Snoqualmie        9102 non-null   int64  \n",
      " 61  city_grouped_Tukwila           9102 non-null   int64  \n",
      " 62  city_grouped_Vashon            9102 non-null   int64  \n",
      " 63  city_grouped_Woodinville       9102 non-null   int64  \n",
      " 64  knn_avg_price                  9102 non-null   float64\n",
      " 65  zipcode_price_tier_Medium      9102 non-null   int64  \n",
      " 66  zipcode_price_tier_High        9102 non-null   int64  \n",
      " 67  floors_bin_2                   9102 non-null   int64  \n",
      " 68  floors_bin_3+                  9102 non-null   int64  \n",
      "dtypes: float64(16), int64(53)\n",
      "memory usage: 4.9 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              log_price   R-squared:                       0.795\n",
      "Model:                            OLS   Adj. R-squared:                  0.794\n",
      "Method:                 Least Squares   F-statistic:                     1278.\n",
      "Date:                Tue, 15 Apr 2025   Prob (F-statistic):               0.00\n",
      "Time:                        12:37:04   Log-Likelihood:                -151.12\n",
      "No. Observations:                7281   AIC:                             348.2\n",
      "Df Residuals:                    7258   BIC:                             506.8\n",
      "Df Model:                          22                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         13.0661      0.003   4504.603      0.000      13.060      13.072\n",
      "x1          1.377e+10   1.04e+11      0.132      0.895   -1.91e+11    2.18e+11\n",
      "x2           1.19e+10   9.01e+10      0.132      0.895   -1.65e+11    1.89e+11\n",
      "x3             0.0049      0.003      1.622      0.105      -0.001       0.011\n",
      "x4             0.0324      0.004      7.808      0.000       0.024       0.041\n",
      "x5         -1.083e+07    8.2e+07     -0.132      0.895   -1.72e+08     1.5e+08\n",
      "x6             0.0474      0.003     13.980      0.000       0.041       0.054\n",
      "x7             0.0313      0.004      8.664      0.000       0.024       0.038\n",
      "x8           3.56e+07   2.69e+08      0.132      0.895   -4.92e+08    5.64e+08\n",
      "x9            -1.1533      0.319     -3.611      0.000      -1.779      -0.527\n",
      "x10           -0.0233      0.006     -3.955      0.000      -0.035      -0.012\n",
      "x11          3.56e+07   2.69e+08      0.132      0.895   -4.92e+08    5.64e+08\n",
      "x12            0.1218      0.003     38.491      0.000       0.116       0.128\n",
      "x13            0.1755      0.037      4.770      0.000       0.103       0.248\n",
      "x14            1.1514      0.317      3.631      0.000       0.530       1.773\n",
      "x15         1.083e+07    8.2e+07      0.132      0.895    -1.5e+08    1.72e+08\n",
      "x16            0.0844      0.038      2.206      0.027       0.009       0.159\n",
      "x17            0.0181      0.088      0.206      0.837      -0.154       0.191\n",
      "x18        -2.262e+10   1.71e+11     -0.132      0.895   -3.58e+11    3.13e+11\n",
      "x19            0.1508      0.137      1.100      0.271      -0.118       0.419\n",
      "x20            0.1415      0.140      1.014      0.311      -0.132       0.415\n",
      "x21           -0.1871      0.050     -3.738      0.000      -0.285      -0.089\n",
      "x22            0.0432      0.003     12.813      0.000       0.037       0.050\n",
      "x23            0.0743      0.005     16.101      0.000       0.065       0.083\n",
      "x24            0.1628      0.005     31.981      0.000       0.153       0.173\n",
      "x25            0.0334      0.004      7.729      0.000       0.025       0.042\n",
      "==============================================================================\n",
      "Omnibus:                     5683.284   Durbin-Watson:                   2.005\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           532996.495\n",
      "Skew:                          -3.087   Prob(JB):                         0.00\n",
      "Kurtosis:                      44.458   Cond. No.                     2.22e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 8.17e-29. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "# Fit the pipeline on the training data\n",
    "ols_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Access the statsmodels OLS results via the custom wrapper\n",
    "ols_results = ols_pipeline.named_steps['reg']\n",
    "\n",
    "# Print the full regression output\n",
    "print(ols_results.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression Summary:\n",
      "               Feature  Coefficient\n",
      "0            Intercept    13.066131\n",
      "1             bedrooms    -0.033703\n",
      "2            bathrooms     0.041230\n",
      "3             sqft_lot     0.004708\n",
      "4               floors     0.036089\n",
      "5           waterfront     0.011052\n",
      "6                 view     0.045268\n",
      "7            condition     0.030034\n",
      "8             yr_built    -0.020480\n",
      "9         yr_renovated    -0.000526\n",
      "10  yr_after_renovated    -0.006805\n",
      "11      yr_after_built     0.020480\n",
      "12      price_per_sqft     0.120300\n",
      "13    basement_present     0.039438\n",
      "14        if_renovated     0.006613\n",
      "15       if_waterfront     0.011052\n",
      "16      basement_ratio     0.022949\n",
      "17    sqft_above_ratio    -0.004753\n",
      "18               rooms     0.001178\n",
      "19     log_sqft_living     0.144977\n",
      "20      log_sqft_above     0.135275\n",
      "21   log_sqft_basement    -0.013919\n",
      "22             zipcode     0.043058\n",
      "23      city_avg_price     0.075589\n",
      "24   zipcode_avg_price     0.159842\n",
      "25       knn_avg_price     0.034454\n"
     ]
    }
   ],
   "source": [
    "# Fit the ridge pipeline on my training data\n",
    "ridge_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Access the trained ridge regressor from the pipeline\n",
    "ridge_reg = ridge_pipeline.named_steps['reg']\n",
    "\n",
    "# Retrieve coefficients and intercept\n",
    "ridge_coef = ridge_reg.coef_\n",
    "ridge_intercept = ridge_reg.intercept_\n",
    "\n",
    "# Create a summary table with feature names\n",
    "# Get feature names from X_train (assumes X_train is a DataFrame)\n",
    "features = X_train.columns\n",
    "ridge_summary = pd.DataFrame({\n",
    "    'Feature': ['Intercept'] + list(features),\n",
    "    'Coefficient': [ridge_intercept] + list(ridge_coef)\n",
    "})\n",
    "\n",
    "print(\"Ridge Regression Summary:\")\n",
    "print(ridge_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression Summary:\n",
      "               Feature  Coefficient\n",
      "0            Intercept    13.066131\n",
      "1             bedrooms     0.000000\n",
      "2            bathrooms     0.000000\n",
      "3             sqft_lot     0.000000\n",
      "4               floors     0.000000\n",
      "5           waterfront     0.000000\n",
      "6                 view     0.000000\n",
      "7            condition     0.000000\n",
      "8             yr_built    -0.000000\n",
      "9         yr_renovated    -0.000000\n",
      "10  yr_after_renovated     0.000000\n",
      "11      yr_after_built     0.000000\n",
      "12      price_per_sqft     0.032557\n",
      "13    basement_present     0.000000\n",
      "14        if_renovated    -0.000000\n",
      "15       if_waterfront     0.000000\n",
      "16      basement_ratio     0.000000\n",
      "17    sqft_above_ratio    -0.000000\n",
      "18               rooms     0.000000\n",
      "19     log_sqft_living     0.182775\n",
      "20      log_sqft_above     0.000000\n",
      "21   log_sqft_basement     0.000000\n",
      "22             zipcode     0.000000\n",
      "23      city_avg_price     0.001875\n",
      "24   zipcode_avg_price     0.165406\n",
      "25       knn_avg_price     0.062225\n"
     ]
    }
   ],
   "source": [
    "# Fit the lasso pipeline on my training data\n",
    "lasso_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Access the trained lasso regressor from the pipeline\n",
    "lasso_reg = lasso_pipeline.named_steps['reg']\n",
    "\n",
    "# Retrieve coefficients and intercept\n",
    "lasso_coef = lasso_reg.coef_\n",
    "lasso_intercept = lasso_reg.intercept_\n",
    "\n",
    "# Create a summary table with feature names\n",
    "features = X_train.columns\n",
    "lasso_summary = pd.DataFrame({\n",
    "    'Feature': ['Intercept'] + list(features),\n",
    "    'Coefficient': [lasso_intercept] + list(lasso_coef)\n",
    "})\n",
    "\n",
    "print(\"Lasso Regression Summary:\")\n",
    "print(lasso_summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
